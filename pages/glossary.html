<!-- ZÁKLADNÍ POJMY / GLOSÁŘ -->
<section id="glossary">
  <div class="section section--white">
    <h1 class="section__title">Základní pojmy</h1>
    <div class="section__body">
      <p>
        Tento slovníček shrnuje základní pojmy, se kterými se setká každý, kdo chce jazykové modely používat vědomě a smysluplně. Nabízí praktický rámec pro pochopení toho, proč model někdy odpovídá nepřesně a jakým způsobem formulace zadání ovlivňuje výsledek.
      </p>

      <!-- Navigace - kompaktní tagy -->
      <nav class="glossary-tags" aria-label="Slovníček pojmů">
        <button class="glossary-tag" data-term="prompt">Prompt</button>
        <button class="glossary-tag" data-term="prompt-engineering">Prompt engineering</button>
        <button class="glossary-tag" data-term="fewshot">Few-shot / Zero-shot</button>
        <button class="glossary-tag" data-term="messages">System / User / Assistant</button>
        <button class="glossary-tag" data-term="temperature">Temperature</button>
        <button class="glossary-tag" data-term="kontext">Kontextové okno</button>
        <button class="glossary-tag" data-term="tokeny">Tokeny</button>
        <button class="glossary-tag" data-term="embeddingy">Embeddingy</button>
        <button class="glossary-tag" data-term="halucinace">Halucinace</button>
        <button class="glossary-tag" data-term="bias">Zkreslení (bias)</button>
        <button class="glossary-tag" data-term="reasoning">Reasoning modely</button>
        <button class="glossary-tag" data-term="finetuning">Fine-tuning</button>
        <button class="glossary-tag" data-term="rag">RAG</button>
      </nav>

      <!-- Sdílený panel pro obsah -->
      <article class="glossary-detail" id="glossary-detail" hidden>
        <header class="glossary-detail__header">
          <h2 class="glossary-detail__title"></h2>
          <button class="glossary-detail__close" aria-label="Zavřít">×</button>
        </header>
        <div class="glossary-detail__body"></div>
      </article>

      <!-- Obsah pojmů (skrytý, JS ho kopíruje do detail panelu) -->
      <div class="glossary-terms" hidden>

        <!-- PROMPT -->
        <div data-term="prompt">
          <h2>Prompt</h2>
          <p>
            Prompt je vstupní sdělení, kterým člověk formuluje zadání pro LLM. Zjednodušeně řečeno jde o to, co uživatel napíše (nebo řekne) do vstupního okénka nástroje jako je ChatGPT. Prompt poskytuje modelu kontext na jehož základě je vytvořena odpověď. Prompt může mít podobu otázky, instrukce, ukázky, role nebo jejich kombinace a nemusí být omezen pouze na text. Může zahrnovat také obraz, zvuk, video nebo jiné vstupy.
          </p>
          <p>
            Z pohledu modelu nejde o příkaz v lidském smyslu, ale o popis situace, ze kterého model odvozuje nejpravděpodobnější pokračování. U multimodálních modelů je tento popis vytvářen souhrnně z různých typů vstupů, které se navzájem doplňují a společně vymezují významový rámec zadání.
          </p>
          <p>
            Lze jej chápat jako zadání úlohy, otevření dialogu nebo metaforicky jako scénář, který určuje, o čem se bude „mluvit". Kvalita a přesnost promptu mají zásadní vliv na srozumitelnost, relevanci i užitečnost výsledné odpovědi.
          </p>
        </div>

        <!-- PROMPT ENGINEERING -->
        <div data-term="prompt-engineering">
          <h2>Prompt engineering</h2>
          <p>
            Prompt engineering je praxe navrhování vstupních sdělení (promptů) pro LLMs tak, aby výstupy modelu byly co nejrelevantnější. Jedná se o vědomé strukturování zadání, které modelu poskytuje kontext, očekávání, kritéria pro odpověď. Kvalitní prompt výrazně ovlivňuje kvalitu generovaného výstupu ve všech podporovaných režimech (text, obraz, zvuk či jiné multimodální vstupy).
          </p>
          <p>
            Pro praktické techniky, vzory a detailní vysvětlení viz <a href="#prompting">kapitolu o promptování</a>.
          </p>
        </div>

        <!-- FEW-SHOT / ZERO-SHOT -->
        <div data-term="fewshot">
          <h2>Few-shot / Zero-shot</h2>
          <p>
            Few-shot a zero-shot jsou techniky používané při práci s LLMs, které jsou založeny na poskytnutí ukázek požadovaného výstupu před vykonáním instrukce.
          </p>
          <p>
            <b>Zero-shot</b> označuje situaci, kdy model dostane úkol pouze s instrukcemi a kontextem, ale bez jakýchkoli ukázkových příkladů. Model v takovém případě spoléhá na svoji předchozí „znalost" získanou během tréninku.
          </p>
          <p>
            <b>Few-shot</b> znamená, že prompt obsahuje malý počet konkrétních ukázkových příkladů, které demonstrují, jak úlohu řešit. Tyto příklady modelu usnadňují pochopení formátu a stylu očekávaného výstupu a obvykle zlepšují výsledky ve specifickém kontextu.
          </p>
          <p>
            Obě techniky využívají schopnost modelů generalizovat z omezeného kontextu bez nutnosti zásadní úpravy základního modelu. Zero-shot je vhodný pro obecné úkoly bez dostupných příkladů, zatímco few-shot je často efektivnější, když několik příkladů dokáže model lépe „nastavit" na konkrétní úlohu.
          </p>
          <p>
            Ve vývojových knihovnách jako <a href="https://github.com/google/langextract" target="_blank" rel="noopener noreferrer">LangExtract</a> se principy few-shot příkladů používají k definování extrakčních úloh a řízení strukturovaného výstupu modelu z nestrukturovaného textu — bez potřeby trénování vlastního modelu. Více viz <a href="#prompting">kapitola o promptování</a>.
          </p>
        </div>

        <!-- SYSTEM / USER / ASSISTANT -->
        <div data-term="messages">
          <h2>System / User / Assistant</h2>
          <p>
            Při práci s ChatGPT a podobnými nástroji se rozhovor interně dělí na tři typy zpráv, kterým se říká role: <b>system</b>, <b>user</b> a <b>assistant</b>. Tyto role pomáhají modelu rozlišit, co je nastavení chování, co je dotaz od člověka a co je odpověď modelu.
          </p>
          <p>
            <b>System</b> určuje, jak se má asistent chovat. Patří sem například tón odpovědí, styl psaní nebo obecná pravidla. V běžném používání ChatGPT se tato role projevuje hlavně v nastavení nebo při vytváření vlastního asistenta.
          </p>
          <p>
            <b>User</b> je to, co uživatel píše do chatu — otázky, požadavky a úkoly.
          </p>
          <p>
            <b>Assistant</b> je odpověď, kterou model vygeneruje.
          </p>
          <p>
            Běžný uživatel se o roli assistant nestará a role user odpovídá jednoduše tomu, co píše do okna chatu. Důležitá je především role system, protože umožňuje předem ovlivnit chování asistenta, aniž by bylo nutné to opakovat v každém dotazu.
          </p>
          <p>
            V běžném webovém rozhraní ChatGPT jsou tyto role většinou skryté a uživatel s nimi pracuje nepřímo. Při programovém použití (přes API) lze role zadávat explicitně.
          </p>
        </div>

        <!-- TEMPERATURE -->
        <div data-term="temperature">
          <h2>Temperature</h2>
          <p>
            Temperature (teplota) je parametr jazykového modelu, který ovlivňuje míru náhodnosti a kreativity odpovědí. Určuje, jak „odvážně" model vybírá další slova při generování textu.
          </p>
          <p>
            Při <b>nízké teplotě</b> model volí převážně nejpravděpodobnější pokračování, takže odpovědi jsou stabilní, přesné a předvídatelné. To je vhodné pro faktické dotazy, shrnutí, analýzy nebo technické texty.
          </p>
          <p>
            Při <b>vyšší teplotě</b> model připouští méně pravděpodobné varianty, což vede k kreativnějším, rozmanitějším, ale i méně konzistentním odpovědím. To se hodí pro brainstorming, psaní textů nebo generování nápadů.
          </p>
          <p>
            V běžném webovém rozhraní ChatGPT uživatel teplotu obvykle nenastavuje přímo. Její vliv lze nepřímo ovlivnit formulací promptu, například pokyny typu „buď kreativní" nebo „odpovídej přesně a stručně".
          </p>
          <p>
            Při použití API nebo vývojových nástrojů lze teplotu nastavovat explicitně jako číselnou hodnotu nebo pomocí posuvníku, typicky podle požadovaného typu výstupu (nízká teplota pro faktické shrnutí, vyšší teplota pro nápady).
          </p>
          <p>
            Příkladem nástroje, kde lze teplotu přímo nastavovat a sledovat její vliv na chování modelu, je <a href="https://aistudio.google.com/" target="_blank" rel="noopener noreferrer">Google AI Studio</a>, které umožňuje experimentovat s různými hodnotami a porovnávat výsledky.
          </p>
          <p>
            Temperature tedy nemění znalosti modelu, ale způsob, jakým z nich vybírá a kombinuje odpověď.
          </p>
        </div>

        <!-- KONTEXTOVÉ OKNO -->
        <div data-term="kontext">
          <h2>Kontextové okno</h2>
          <p>
            Jedním ze základních, ale často přehlížených omezení velkých jazykových modelů je tzv.
            <b>kontextové okno</b>. To určuje, kolik informací je model schopen vzít v úvahu v jednom okamžiku —
            tedy kolik textu „vidí", když generuje odpověď. Porozumění tomuto pojmu je zásadní pro efektivní práci s
            generativní AI a odpovídá na otázku, proč modely někdy „zapomínají" dříve uvedené informace.
          </p>
          <p>
            Kontextové okno je maximální množství tokenů, které model dokáže zpracovat najednou. Zahrnuje přitom:
          </p>
          <ul>
            <li>zadání (prompt),</li>
            <li>historie konverzace,</li>
            <li>generovaný text.</li>
          </ul>
          <p>
            Jakmile je tato kapacita vyčerpána, model starší části kontextu přestává „vidět". Neznamená to, že by je zapomněl
            v lidském smyslu — jednoduše už nejsou součástí aktuálního výpočtu.
          </p>

          <!-- Obrázek Kontextove okno -->
          <figure class="image-card">
            <div class="image-card__frame">
            <div class="hotspot-image">
              <img src="img/context.png" alt="Schéma kontextového okna" loading="lazy" decoding="async"/>
            </div>
            </div>
            <figcaption class="image-card__caption">
              <h3 class="image-card__title">Rozsah kontextového okna</h3>
              <p class="image-card__meta">
                Počet tokenů, které model dokáže zpracovat najednou, je omezený. Různé typy a verze modelů mají různě velká kontextová okna.
                Kontextové okno zahrnuje nejen vstupní text a vygenerovaný obsah, ale i využití různych doplňkových nástrojů a funkcí.
                <br>
                Obrázek byl převzat z dokumentace
                <a href="https://platform.claude.com/docs/en/build-with-claude/context-windows#context-awareness-in-claude-sonnet-4-5-and-haiku-4-5" class="link--subtle">
                Claude Docs
                </a>.
              </p>
            </figcaption>
          </figure>

          <p>
            Kapacitu kontextového okna je třeba mít na paměti při řešení komplexních úloh, které vyžadují
            zpracování velkého množství informací - dlouhých dokumentů, rozsáhlých konverzací apod. Doporučujeme
            sledovat aktuální dokumentaci k používanému modelu.
          </p>
          <p>
            Že jste dorazili na hranici kontextového okna poznáte podle toho, že <b>model začne
            ignorovat</b> dříve uvedené informace nebo pokyny, začne opakovat fráze, nebo odpovědi přestanou navazovat.
            V takovém případě je potřeba prompt buď zkrátit, nebo úlohu rozdělit na menší části.
          </p>
          <p>
            Abyste kontextové okno nezahltili zbytečnými informacemi, je vhodné pro každý úkol, úlohu nebo dotaz (či jejich sérii)
            použít <b>nové kontextové okno</b>. Toto kontextové okno může mít různou podobu v závislosti na konkrétním modelu.
            All-purpose modely jako ChatGPT, Claude nebo Gemini vedou historii dotazů jako seznam konverzací,
            jejichž název model automaticky generuje na základě prvního dotazu. Specializované modely jako například
            NotebookLM, které nejsou založeny pouze na klasickém dialogu, pak mohou kontextové okno reprezentovat jako
            jednotlivé dokumenty, poznámky nebo jiné textové bloky.
          </p>

          <!-- Int. Obr: Kontextová okna -->
          <figure class="image-card">
            <div class="image-card__frame">
            <div class="hotspot-image">
              <img src="img/kontextova_okna.png" alt="Příklad kontextového okna" loading="lazy" decoding="async"/>

              <!-- Hotspot -->
              <div class="hotspot" style="left: 10%; top: 10%;">
                <div class="hotspot__tooltip hotspot__tooltip--below" role="tooltip" hidden>
                  <strong>ChatGPT</strong>
                </div>
              </div>

              <!-- Hotspot -->
              <div class="hotspot" style="left: 40%; top: 5%;">
                <div class="hotspot__tooltip hotspot__tooltip--below" role="tooltip" hidden>
                  <strong>Claude</strong>
                </div>
              </div>

              <!-- Hotspot -->
              <div class="hotspot" style="left: 50%; top: 73%;">
                <div class="hotspot__tooltip" role="tooltip" hidden>
                  <strong>NotebookLM</strong><br>
                </div>
              </div>
            </div>
          </div>

            <figcaption class="image-card__caption">
              <h3 class="image-card__title">Jak může vypadat seznam kontextových oken</h3>
              <p class="image-card__meta">
                Modely, k nimž se přistupuje prostřednictvím webového prohlížeče, ukládají historii
                konverzací jako seznam jednotlivých chatů nebo dokumentů. Při zahájení nové konverzace vzniká
                nové kontextové okno, které neobsahuje předchozí dotazy a odpovědi, bere ovšem v potaz
                uživatelská nastavení a preference, které lze u některých modelů upravit.
              </p>
            </figcaption>
          </figure>
        </div>

        <!-- TOKENY -->
        <div data-term="tokeny">
          <h2>Tokeny</h2>
          <p>
            Token je základní jednotka textu, se kterou velké jazykové modely (LLM) pracují. Tokeny nevznikají samy o sobě, ale jsou výsledkem procesu zvaného tokenizace, při němž je vstupní text rozdělen na menší části podle definovaných pravidel. Token může odpovídat celému slovu, části slova, interpunkčnímu znaménku, mezeře nebo jejich kombinaci.
          </p>
          <p>
            Při popisu kapacity kontextového okna jazykových modelů (tedy kolik textu je model schopen najednou zpracovat) se proto běžně používá počet tokenů, nikoli počet znaků nebo slov.
          </p>
          <h3>Tokenizéry a modely</h3>
          <p>
            Každý jazykový model je trénován s konkrétním tokenizérem. Různé modely mohou používat odlišné způsoby tokenizace, a proto stejný text může být různými modely rozdělen na rozdílný počet tokenů. Tokenizéry jsou obvykle navrženy tak, aby efektivně reprezentovaly běžné jazykové vzory: častá slova nebo jejich části bývají reprezentovány jedním tokenem, zatímco méně časté nebo neobvyklé výrazy se skládají z více tokenů.
          </p>
          <h3>Kolik tokenů má text?</h3>
          <p>
            Průměrné anglické slovo odpovídá přibližně 1,3 tokenu, přičemž konkrétní hodnota závisí na použitém tokenizéru a jazyce. Při tomto hrubém odhadu lze uvést, že trilogie Pán prstenů obsahuje zhruba 800 000 tokenů, kompletní dílo Williama Shakespeara asi 1,2 milionu tokenů a série Píseň ledu a ohně přes 2 miliony tokenů. Tyto hodnoty je však nutné chápat pouze orientačně.
          </p>
        </div>

        <!-- EMBEDDINGY -->
        <div data-term="embeddingy">
          <h2>Embeddingy</h2>
          <p>
            Embedding označuje proces nebo výsledek procesu reprezentace tokenů ve vysokodimenzionálním prostoru. Poloha vektoru vyjadřuje význam, který mu model v daném kontextu přisuzuje. Tokeny s podobným významem leží blízko sebe, zatímco významově nesouvisející pojmy jsou v prostoru vzdálenější. Model tak s jazykem pracuje jako s geometrickou strukturou, nikoli jako s pouhou posloupností slov.
          </p>
          <p>
            Vizualizaci embeddingu v interaktivním prostředí lze vyzkoušet v nástroji <a href="https://projector.tensorflow.org/" target="_blank" rel="noopener noreferrer">TensorFlow Embedding Projector</a>.
          </p>
          <p>
            Význam se v této reprezentaci projevuje geometricky pomocí vzdáleností a směrů mezi vektory. Nejde o explicitní pojmy nebo pravidla, ale o struktury, které se v prostoru vytvářejí na základě učení z velkého množství jazykových dat. Klasickým příkladem je vztah:
          </p>
          <pre>král − muž + žena ≈ královna</pre>
          <p>
            který ukazuje, že určitý významový rozdíl se v prostoru chová jako konzistentní směr. Podobné směry se objevují i u dalších dvojic slov (např. herec ↔ herečka, princ ↔ princezna) a odpovídají různým aspektům významu, jako je pohlaví, role, míra abstrakce, časové zasazení či emocionální zabarvení. Jednotlivé rozměry samy o sobě nemají jednoduchý výklad, smysl vzniká až jejich kombinací.
          </p>
          <p>
            Stejné slovo může mít v různých kontextech odlišnou reprezentaci, například „klíč" ve větě „ztratil jsem klíč od dveří" a ve spojení „houslový klíč". Význam je vždy vyhodnocován vzhledem k okolnímu kontextu, což umožňuje práci s víceznačností a jemnými významovými nuancemi.
          </p>
          <p>
            Embedding tvoří základ porozumění významu textu a navazujících schopností jazykových modelů, jako je porovnávání podobnosti, práce s kontextem, vyhledávání relevantních informací nebo techniky typu RAG. Bez nich by model pracoval pouze s posloupností symbolů, nikoli s významem.
          </p>
        </div>

        <!-- HALUCINACE -->
        <div data-term="halucinace">
          <h2>Halucinace</h2>
          <p>
            Halucinace označují situace, kdy LLMs vytváří odpovědi, které znějí přesvědčivě, ale nejsou fakticky správné nebo si je model drze vymyslel. Jedním z hlavních důvodů halucinací je to, že jazykový model je navržen tak, aby vždy nějak odpověděl. Pokud nemá dostatek informací, je dotaz nejasný nebo odpověď v datech není jednoznačná, model přesto pokračuje v generování textu a „doplní mezery" tím, co mu statisticky dává smysl. Model tedy neověřuje pravdivost, ale vybírá pravděpodobné pokračování textu.
          </p>
          <p>
            Riziko halucinací se zvyšuje například při dotazech na velmi specifická nebo neověřená fakta, při požadavcích na přesné citace, při vysoké míře kreativity nebo při nedostatku kontextu. Naopak je lze omezit jasným zadáním, připuštěním nejistoty („pokud nevíš, řekni to"), prací se zdroji nebo strukturovanějším promptováním.
          </p>
          <p>
            Halucinace nejsou chybou ve smyslu selhání paměti, ale přirozeným důsledkem toho, jak jazykové modely fungují. Konkrétní techniky, jak riziko halucinací snížit pomocí vhodného promptování, jsou popsány v <a href="#prompting">kapitole o promptování</a>.
          </p>
        </div>

        <!-- BIAS -->
        <div data-term="bias">
          <h2>Zkreslení (bias)</h2>
          <p>
            Jazykové modely se učí z velkých textových korpusů, které odrážejí svět takový, jaký je — včetně jeho nerovností, stereotypů a
            historických zkreslení. Pokud se určitý pohled nebo skupina v datech vyskytuje častěji, model má tendenci jej reprodukovat.
          </p>
          <p>To může vést například k:</p>
          <ul>
            <li><b>Genderovým stereotypům:</b> Pokud model častěji spojuje určité profese s určitým pohlavím (např. „sestra" vs. „lékař"), může tyto stereotypy posilovat.</li>
            <li><b>Kulturnímu zkreslení:</b> Anglicky psané korpusy dominují, což může vést k preferenci západní perspektivy a menší reprezentaci jiných kultur.</li>
            <li><b>Historickému kontextu:</b> Data zahrnují texty z různých období, včetně zastaralých pohledů, které dnes nejsou přijatelné.</li>
            <li><b>Nedostatečnému zastoupení menšin:</b> Menšinové skupiny mohou být v datech podreprezentované, což vede k méně přesnému nebo citlivému výstupu.</li>
          </ul>
          <p>
            Ve výzkumném prostředí je proto důležité:
          </p>
          <ul>
            <li>ověřovat výstupy modelu z důvěryhodných zdrojů,</li>
            <li>být si vědom možných zkreslení při interpretaci výsledků,</li>
            <li>nepoužívat model jako jediný zdroj informací v citlivých oblastech (např. při hodnocení osob, kulturních kontextů nebo etických dilemat).</li>
          </ul>
        </div>

        <!-- REASONING MODELY -->
        <div data-term="reasoning">
          <h2>Reasoning modely</h2>
          <p>
            Některé velké jazykové modely jsou speciálně navržené pro lepší zvládání logických úloh,
            matematických výpočtů a komplexního uvažování. Tyto modely, označované jako <b>reasoning modely</b>,
            často zahrnují mechanismy pro provádění mezikroků a ověřování výsledků.
          </p>
          <p>
            Rozdíl mezi běžným a reasoning LLM modelem je ve způsobu, jakým model generuje odpověď.
            Zatímco běžný LLM se často snaží rychle dospět k výsledku, reasoning model je trénován k tomu,
            aby si problém „rozložil", postupoval krok za krokem a jednotlivé části řešení na sebe navazovaly.
            To vede k pomalejším, ale obvykle konzistentnějším odpovědím, zejména u složitějších zadání.
          </p>
          <p>
            Jak poznáte, že je model v režimu <i>reasoning</i>? Samotná informace o tom, zda je toho schopen,
            je uvedena v dokumentaci. Aktivace reasoning režimu pak závisí na konkrétním modelu, přičemž občas
            je tato funkce dostupná pouze v placených verzích. Název samotného reasoning režimu pak často zahrnuje
            pojem "thinking".
          </p>
          <h3>Trénování reasoning modelu</h3>
          <p>
            Reasoning modely vycházejí ze stejných architektur jako ostatní LLMs, ale liší se způsobem ladění a typem úloh,
            na kterých byly trénovány. Během učení jsou systematicky vystavovány úlohám, kde není možné uspět jedním
            „intuitivním" krokem, ale je potřeba:
          </p>
          <ul>
            <li>rozložit problém na menší části,</li>
            <li>aplikovat zadaná pravidla nebo omezení,</li>
            <li>ověřit mezivýsledky,</li>
            <li>a dospět k závěru na základě dané posloupnosti kroků.</li>
          </ul>
          <p>
            Při trénování se často pracuje s příklady, kde je explicitně ukázán postup řešení, nikoli pouze finální odpověď.
            Model se tak neučí jen co odpovědět, ale jak k odpovědi dojít. V praxi to znamená, že je schopen lépe řešit
            úlohy typu „pokud–pak" nebo kombinovat více podmínek najednou.
          </p>
          <h3>Uplatnění reasoning modelů</h3>
          <p>
            Tento typ modelů se uplatňuje při řešení úloh, které nevyžadují pouze (stylisticky) srozumitelný
            výsledek, ale závisí na správnosti postupu. Hodí se pro řešení analytických úloh, interpretaci
            předpisů, metodik nebo pravidel, návrhu rozhodovacích stromů nebo zodpovídání otázek typu
            "co by se stalo, kdyby...".
          </p>
          <p>
            Reasoning modely odpovědi poskytují pomaleji (občas i v řádu desítek sekund), a to ve prospěch
            kvality výstupu. Jsou ovšem oblasti, kde je jejich použití nevhodné nebo nadbytečné. Jedná
            se o úlohy, ve kterých jde o kreativní psaní, stylistickou úpravu textu nebo například shrnutí textu.
            V těchto případech je rychlejší a efektivnější použít obecný jazykový model.
          </p>
        </div>

        <!-- FINE-TUNING -->
        <div data-term="finetuning">
          <h2>Fine-tuning</h2>
          <p>
            Fine-tuning je způsob, jak trvale upravit základní jazykový model tak, aby lépe odpovídal konkrétnímu prostředí nebo způsobu práce. Model se dodatečně trénuje na vybraných datech a výsledkem je nová verze modelu, která se chová jinak než původní.
          </p>
          <p>
            V prostředí ústavu by fine-tuning znamenal, že se model učí z interních dokumentů (směrnice, příkazy ředitele, metodické pokyny) nebo z příkladů otázek a odpovědí, aby dlouhodobě odpovídal ve správném stylu, používal interní terminologii a „rozuměl" logice organizace. Model si tento způsob chování nese v sobě a není nutné jej znovu nastavovat v každém dotazu.
          </p>
          <p>
            Technicky se fine-tuning provádí na specializovaných platformách (např. IBM watsonx, Google Vertex AI), které vezmou hotový model a vytvoří jeho upravenou variantu. Tím se ale zároveň mění samotný model: pokud se dokumenty změní, je nutné model znovu ladit.
          </p>
          <p>
            Fine-tuning je proto vhodný hlavně tam, kde je cílem dlouhodobě změnit chování modelu (styl, jazyk, konzistence), ale méně vhodný pro práci s často se měnícím obsahem nebo tam, kde je nutné přesně doložit zdroj informací. Pro tyto účely se častěji používá <a href="#rag">RAG</a>, který lze s fine-tuningem kombinovat.
          </p>
        </div>

        <!-- RAG -->
        <div data-term="rag">
          <h2>RAG (Retrieval-Augmented Generation)</h2>
          <p>
            RAG (Retrieval-Augmented Generation) je přístup, kterým se dnes obchází jedno ze základních omezení LLMs – délka kontextového okna. Pokud potřebujete pracovat s rozsáhlou databází dokumentů, které nelze vměstnat do kontextového okna, můžete model instruovat, ať hledá v externích dokumentech. V ústavním prostředí by RAG například znamenal, že směrnice, příkazy ředitele a další dokumenty zůstávají uloženy mimo model. Při dotazu se vždy vyberou jen relevantní části těchto dokumentů a vloží se do kontextu odpovědi. Model tedy odpovídá podle aktuálního znění dokumentů, nikoli podle „paměti".
          </p>
          <p>
            Technickým základem RAG je vektorová databáze, která ukládá dokumenty ve formě jejich významových reprezentací (viz <a href="#embeddingy">embeddingy</a>). Díky tomu lze vyhledávat podle významu, nikoli jen podle shody slov, a zároveň se do kontextu modelu dostává jen malý, relevantní výřez textu. Tím RAG řeší i omezenou velikost kontextového okna.
          </p>
          <p>
            Zásadní výhodou RAG je, že nad stejnou databází dokumentů lze používat různé jazykové modely. Model lze vyměnit nebo aktualizovat bez nutnosti znovu zpracovávat data, protože znalosti zůstávají mimo model. Dokumenty lze také kdykoli aktualizovat bez zásahu do modelu samotného.
          </p>
          <p>
            RAG je tedy vhodný tam, kde je klíčová přesnost a práce s velkým objemem dokumentů. Pro jednotný styl odpovědí se často kombinuje s fine-tuningem, který upraví chování modelu, zatímco RAG dodává konkrétní obsah.
          </p>
          <p>
            Praktickým příkladem nástroje využívajícího RAG je <a href="https://notebooklm.google/" target="_blank" rel="noopener noreferrer">Google NotebookLM</a>, který umožňuje nahrát vlastní dokumenty a následně se nad nimi ptát.
          </p>
        </div>

      </div><!-- /.glossary-terms -->

    </div>
  </div>
</section>
