<!-- BASICS -->
<section id="basics">
  <div class="section section--muted">
    <h2 class="section__title">Jak jazykovÃ© modely skuteÄnÄ› fungujÃ­</h2>
     <div class="section__body">

      <!-- Intro -->

        <p>
          VeÅ™ejnÃ¡ debata o jazykovÃ½ch modelech (LLM) Äasto sklouzÃ¡vÃ¡ ke dvÄ›ma krajnÃ­m polohÃ¡m. Podle jednÄ›ch jsou v zÃ¡sadÄ› k niÄemu a jde jen o nÄ›co chytÅ™ejÅ¡Ã­ naÅ¡eptÃ¡vaÄ z Nokie 3310. Podle druhÃ½ch jde naopak o technologii, kterÃ¡ nÃ¡s pÅ™ipravÃ­ o prÃ¡ci, nebo nÃ¡s rovnou vyhubÃ­ ve stylu Skynetu z TerminÃ¡tora.
        </p>
        <p>
          Pravda je, Å¾e tak trochu platÃ­ obojÃ­ ğŸ™‚, ale stejnÄ› jako u vÄ›tÅ¡iny vÄ›cÃ­ kolem LLM velmi zÃ¡leÅ¾Ã­ na kontextu a na tom, co od nich oÄekÃ¡vÃ¡me.
        </p>
        <p>
          UdÄ›lejme si v tom trochu jasnÄ›ji tÃ­m, Å¾e si struÄnÄ› vysvÄ›tlÃ­me, jak jazykovÃ© modely zhruba fungujÃ­. DÃ­ky tomu zÃ­skÃ¡me realistiÄtÄ›jÅ¡Ã­ pÅ™edstavu o tom, co od nich lze Äekat a kde naopak narÃ¡Å¾ejÃ­ na svÃ© limity. ZamÄ›Å™Ã­me se na tyto zÃ¡kladnÃ­ oblasti: jak se tyto modely uÄÃ­, jak reprezentujÃ­ text a jakÃ½m zpÅ¯sobem generujÃ­ odpovÄ›di.
        </p>

        <p><a href="#AIIntro" class="link--large">â‡£ AI, ML, LLMâ€¦ aneb co je vlastnÄ› co</a></p>
        <p><a href="#NeuronovaSit" class="link--large">â‡£ Co je neuronovÃ¡ sÃ­Å¥</a></p>
        <p><a href="#Transformery" class="link--large">â‡£ Transformery a Attention</a></p>
        <p><a href="#JakSeUci" class="link--large">â‡£ Jak se LLMs uÄÃ­</a></p>
        <p><a href="#ZakladniTrenink" class="link--large">â‡£ ZÃ¡kladnÃ­ jazykovÃ½ trÃ©nink</a></p>
        <p><a href="#Reinforcement" class="link--large">â‡£ Reinforcement learning</a></p>
        <p><a href="#JakChapeText" class="link--large">â‡£ Jak LLM "chÃ¡pe" text</a></p>

        <section id="AIIntro">  </section>
        <h1>AI, ML, LLMâ€¦ aneb co je vlastnÄ› co</h1>
        <p>
          Pojem AI se dnes naduÅ¾Ã­vÃ¡ natolik, Å¾e obÄas pÅ™ipomÃ­nÃ¡ spÃ­Å¡ zaklÃ­nadlo, kterÃ© mÃ¡ pomoci zÃ­skat grant nebo pÅ¯sobit, Å¾e â€jedeme trendy". PojÄme si proto hned na zaÄÃ¡tku alespoÅˆ rÃ¡mcovÄ› ujasnit, co se pod tÃ­mto pojmem skuteÄnÄ› myslÃ­.
        </p>
        <p>
          UmÄ›lÃ¡ inteligence je zastÅ™eÅ¡ujÃ­cÃ­ pojem pro systÃ©my, kterÃ© se chovajÃ­ â€chytÅ™e", od jednoduchÃ½ch pravidlovÃ½ch Å™eÅ¡enÃ­ (napÅ™. filtrovÃ¡nÃ­ e-mailÅ¯) aÅ¾ po pokroÄilÃ© systÃ©my pracujÃ­cÃ­ s komplexnÃ­mi daty. Jednou z oblastÃ­ AI je strojovÃ© uÄenÃ­ kde se systÃ©my uÄÃ­ z dat a tÃ­m zlepÅ¡ujÃ­ svÃ© chovÃ¡nÃ­. Sem spadajÃ­ i neuronovÃ© sÃ­tÄ›, velmi volnÄ› inspirovanÃ© fungovÃ¡nÃ­m lidskÃ©ho mozku. Ty se dnes pouÅ¾Ã­vajÃ­ u Å™ady Ãºloh, kde je potÅ™eba rozpoznÃ¡vat vzory v datech, napÅ™Ã­klad v obrazu, zvuku nebo textu.
        </p>
        <p>
          GenerativnÃ­ modely pak tvoÅ™Ã­ specializovanou skupinu, Äasto zaloÅ¾enou prÃ¡vÄ› na neuronovÃ½ch sÃ­tÃ­ch. Jejich schopnostÃ­ je vytvÃ¡Å™et novÃ½ obsah, jako je text, obrÃ¡zky, zvuk nebo kÃ³d. PatÅ™Ã­ sem i velkÃ© jazykovÃ© modely (LLM), kterÃ© se zamÄ›Å™ujÃ­ na prÃ¡ci s pÅ™irozenÃ½m jazykem a mezi nÄ›Å¾ spadajÃ­ nÃ¡stroje typu ChatGPT.
        </p>
        <p>
          V bÄ›Å¾nÃ© Å™eÄi se pojmy AI a LLM Äasto zamÄ›ÅˆujÃ­. Pokud je vÅ¡ak jasnÃ½ kontext, obvykle to nepÅ™edstavuje problÃ©m.
        </p>

        <!-- Obr. AI / ML / LLM -->
        <figure class="image-card">
          <div class="image-card__frame">
            <img
                src="img/venn_diagram.png"
                alt="VennÅ¯v diagram znÃ¡zorÅˆujÃ­cÃ­ pÅ™ekryv mezi umÄ›lou inteligencÃ­, strojovÃ½m uÄenÃ­m a generativnÃ­mi modely."
                loading="lazy"
                decoding="async"
            />
          </div>
        </figure>

        <!-- Co je neuronovÃ¡ sÃ­Å¥ -->
        <section id="NeuronovaSit"> </section>
        <h1>NeuronovÃ© sÃ­tÄ›, jazykovÃ© modely a proÄ to celÃ© funguje</h1>
        <p>
          NeuronovÃ¡ sÃ­Å¥ je matematickÃ½ model, kterÃ½ je volnÄ› inspirovanÃ½ fungovÃ¡nÃ­m neuronÅ¯ v lidskÃ©m mozku. DÃ¡ se na ni dÃ­vat jako na jakÃ½si â€matematickÃ½ mozek", sloÅ¾enÃ½ z velkÃ©ho mnoÅ¾stvÃ­ propojenÃ½ch uzlÅ¯, kterÃ© spoleÄnÄ› zpracovÃ¡vajÃ­ informace. NeuronovÃ¡ sÃ­Å¥ je popsÃ¡na pomocÃ­ velkÃ©ho mnoÅ¾stvÃ­ parametrÅ¯, kterÃ© urÄujÃ­, jak silnÄ› spolu jednotlivÃ© ÄÃ¡sti sÃ­tÄ› komunikujÃ­. Tyto parametry nejsou pevnÄ› danÃ© a bÄ›hem trÃ©novÃ¡nÃ­ se postupnÄ› upravujÃ­ na zÃ¡kladÄ› dat, aby sÃ­Å¥ dÃ¡vala lepÅ¡Ã­ vÃ½sledky. Pokud mÃ¡ sÃ­Å¥ mnoho vrstev nad sebou, mluvÃ­me o tzv. hlubokÃ© neuronovÃ© sÃ­ti.
        </p>
        <p>
          UÄenÃ­ neuronovÃ© sÃ­tÄ› lze zjednoduÅ¡enÄ› popsat tak, Å¾e sÃ­Å¥ dostane vstup (napÅ™Ã­klad text), kterÃ½ postupnÄ› prochÃ¡zÃ­ jejÃ­mi jednotlivÃ½mi vrstvami, kde se pomocÃ­ vÃ¡Å¾enÃ½ch kombinacÃ­ a nelineÃ¡rnÃ­ch funkcÃ­ vypoÄÃ­tÃ¡ vÃ½slednÃ½ vÃ½stup. Ten se nÃ¡slednÄ› porovnÃ¡ s poÅ¾adovanÃ½m sprÃ¡vnÃ½m vÃ½sledkem. Pokud se vÃ½stup liÅ¡Ã­, dojde k mÃ­rnÃ© ÃºpravÄ› parametrÅ¯. Tento postup se opakuje mnohokrÃ¡t nad rozsÃ¡hlÃ½m mnoÅ¾stvÃ­m dat. Proces, kterÃ½ tyto Ãºpravy Å™Ã­dÃ­, se nazÃ½vÃ¡ zpÄ›tnÃ© Å¡Ã­Å™enÃ­ chyby (backpropagation) a obvykle se kombinuje s optimalizaÄnÃ­mi algoritmy, napÅ™Ã­klad typu SGD (stochastic gradient descent). PrÃ¡vÄ› tÃ­mto zpÅ¯sobem trÃ©novanÃ© hlubokÃ© neuronovÃ© sÃ­tÄ› dnes tvoÅ™Ã­ zÃ¡klad velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).
        </p>
        <p>
          DÃ­ky obrovskÃ©mu mnoÅ¾stvÃ­ parametrÅ¯ a dat se tyto modely dokÃ¡Å¾ou nauÄit sloÅ¾itÃ© jazykovÃ© vzory, napÅ™Ã­klad gramatiku, vÃ½znam slov nebo kontext v delÅ¡Ã­ch textech. NepracujÃ­ vÅ¡ak s vÃ½znamem v lidskÃ©m smyslu, ale s pravdÄ›podobnostnÃ­mi vztahy mezi slovy a jejich posloupnostmi.
        </p>

        <!-- PoznÃ¡mka: VÄ›tÅ¡Ã­ model = lepÅ¡Ã­? -->
        <div class="collapsible" data-collapsible>
          <button class="collapsible__toggle" aria-expanded="false" aria-controls="collapsible-panel-vetsi-model" id="collapsible-button-vetsi-model">
          <b>VÃCE:</b> Je vÄ›tÅ¡Ã­ model automaticky lepÅ¡Ã­?
          </button>

          <div class="collapsible__panel" id="collapsible-panel-vetsi-model" role="region" aria-labelledby="collapsible-button-vetsi-model" hidden>
            <p>
              Ne nutnÄ›. VÅ¾dy zÃ¡leÅ¾Ã­ na konkrÃ©tnÃ­m Ãºkolu. MenÅ¡Ã­, specializovanÃ½ model mÅ¯Å¾e v ÃºzkÃ© oblasti podat lepÅ¡Ã­ vÃ½sledky neÅ¾ nejnovÄ›jÅ¡Ã­ monstrum od OpenAI. NevÃ½hodou je, Å¾e obvykle hÅ¯Å™e zobecÅˆuje a mimo svou specializaci rychle narÃ¡Å¾Ã­ na svÃ© limity. Na druhou stranu je lze Äasto provozovat lokÃ¡lnÄ› na vlastnÃ­m poÄÃ­taÄi a jejich odezva mÅ¯Å¾e bÃ½t vÃ½raznÄ› rychlejÅ¡Ã­ neÅ¾ u velkÃ½ch modelÅ¯ bÄ›Å¾Ã­cÃ­ch v cloudu. MenÅ¡Ã­ modely jsou sviÅ¾nÄ›jÅ¡Ã­, protoÅ¾e potÅ™ebujÃ­ pro predikci niÅ¾Å¡Ã­ poÄet operacÃ­ (hlavnÄ› maticovÃ©ho nÃ¡sobenÃ­). ObecnÄ› sice platÃ­, Å¾e vÄ›tÅ¡Ã­ poÄet parametrÅ¯ Äasto souvisÃ­ s vyÅ¡Å¡Ã­mi schopnostmi modelu nejde vÅ¡ak o univerzÃ¡lnÃ­ pravidlo (viz Chinchilla scaling laws).
            </p>
          </div>
        </div>

        <!-- PoznÃ¡mka: Chinchilla scaling laws -->
        <div class="collapsible" data-collapsible>
          <button class="collapsible__toggle" aria-expanded="false" aria-controls="collapsible-panel-chinchilla" id="collapsible-button-chinchilla">
          <b>VÃCE:</b> VÅ¡echno Å™Ã­dÃ­ ÄinÄily!
          </button>

          <div class="collapsible__panel" id="collapsible-panel-chinchilla" role="region" aria-labelledby="collapsible-button-chinchilla" hidden>
            <p>
              <strong>Chinchilla scaling laws</strong> popisujÃ­ optimÃ¡lnÃ­ vztah mezi velikostÃ­ modelu (poÄet parametrÅ¯) a mnoÅ¾stvÃ­m trÃ©novacÃ­ch dat (poÄet tokenÅ¯) pro danÃ½ vÃ½poÄetnÃ­ rozpoÄet. Studie DeepMind ukÃ¡zala, Å¾e pro dosaÅ¾enÃ­ co nejlepÅ¡Ã­ho vÃ½konu by poÄet trÃ©novacÃ­ch tokenÅ¯ mÄ›l bÃ½t asi 20Ã— vÄ›tÅ¡Ã­ neÅ¾ poÄet parametrÅ¯ modelu a tedy model s 1 mld. parametrÅ¯ by mÄ›l bÃ½t trÃ©novÃ¡n na zhruba 20 mld. tokenÅ¯.
            </p>
            <p>
              V matematickÃ© formÄ› se Chinchilla scaling laws Äasto vyjadÅ™ujÃ­ skrze souvislost mezi vÃ½poÄetnÃ­mi nÃ¡klady $C$, poÄtem parametrÅ¯ $N$ a poÄtem trÃ©novacÃ­ch tokenÅ¯ $D$:
            </p>
            <p style="text-align: center; font-size: 1.2em;">
              $$C \approx C_0 \cdot N \cdot D$$
            </p>
            <p>
              kde $C_0$ je konstanta pÅ™evÃ¡dÄ›jÃ­cÃ­ poÄet operacÃ­ na nÃ¡klady. Po optimalizaci se zjistÃ­, Å¾e optimÃ¡lnÃ­ kombinace $N$ a $D$ minimalizuje chybovou funkci modelu pro danÃ½ rozpoÄet.
            </p>
            <p>
              Chinchilla tÃ­m zpochybnila dÅ™Ã­vÄ›jÅ¡Ã­ pÅ™edstavu, Å¾e vÄ›tÅ¡Ã­ model = lepÅ¡Ã­ model, a mÃ­sto toho doporuÄuje vyvÃ¡Å¾enÃ½ pomÄ›r parametrÅ¯ a dat pro efektivnÄ›jÅ¡Ã­ uÄenÃ­.
            </p>
          </div>
        </div>

        <!-- PoznÃ¡mka: Overfitting a double descent -->
        <div class="collapsible" data-collapsible>
          <button class="collapsible__toggle" aria-expanded="false" aria-controls="collapsible-panel-overfitting" id="collapsible-button-overfitting">
          <b>VÃCE:</b> A nejde to celÃ© proti zÃ¡kladnÃ­m principÅ¯m modelovÃ¡nÃ­?
          </button>

          <div class="collapsible__panel" id="collapsible-panel-overfitting" role="region" aria-labelledby="collapsible-button-overfitting" hidden>
            <p>
              KdyÅ¾ se Å™ekne, Å¾e dneÅ¡nÃ­ hlubokÃ© neuronovÃ© sÃ­tÄ› mohou mÃ­t stovky miliard parametrÅ¯, nÄ›kterÃ½m z vÃ¡s se moÅ¾nÃ¡ na chvÃ­li udÄ›lalo lehce nevolno. KaÅ¾dÃ½, kdo si nÄ›kdy v Excelu zkusil proloÅ¾it pÄ›t datovÃ½ch bodÅ¯ polynomem pÃ¡tÃ©ho stupnÄ›, teÄ automaticky zvedÃ¡ oboÄÃ­ â€“ a to zcela oprÃ¡vnÄ›nÄ›. S tolika parametry totiÅ¾ hrozÃ­ pÅ™euÄenÃ­ (overfitting), tedy situace, kdy se model mÃ­sto obecnÃ©ho porozumÄ›nÃ­ nauÄÃ­ trÃ©novacÃ­ data zpamÄ›ti. PÅ™i trÃ©novÃ¡nÃ­ je pak nutnÃ© proces vÄas zastavit, jinak se schopnost modelu zobecÅˆovat zaÄne zhorÅ¡ovat. CÃ­lem totiÅ¾ nenÃ­ vychovat â€tÅ™Ã­dnÃ­ho Å¡prta", kterÃ½ se nauÄÃ­ uÄebnici slovo od slova, ale spÃ­Å¡e trochu lajdÃ¡ckÃ©ho gÃ©nia, kterÃ½ si dokÃ¡Å¾e poradit i s Ãºlohami, kterÃ© nikdy pÅ™edtÃ­m nevidÄ›l.
            </p>
            <p>
              ZajÃ­mavÃ© (a pro intuici trochu zneklidÅˆujÃ­cÃ­) je, Å¾e u velmi velkÃ½ch hlubokÃ½ch sÃ­tÃ­ se Äasto pozoruje opaÄnÃ½ efekt. KdyÅ¾ model dÃ¡l zvÄ›tÅ¡ujeme a pÅ™idÃ¡vÃ¡me dalÅ¡Ã­ vrstvy a parametry, v urÄitÃ©m bodÄ› se jeho schopnost zobecÅˆovat zaÄne znovu zlepÅ¡ovat. Tento jev se oznaÄuje jako double descent a dodnes nenÃ­ ÃºplnÄ› vysvÄ›tlen.
            </p>
            <p>
              Jednou z moÅ¾nÃ½ch interpretacÃ­ je tzv. hypotÃ©za vÃ½hernÃ­ho losu (lottery ticket hypothesis). Ta Å™Ã­kÃ¡, Å¾e v obÅ™Ã­ neuronovÃ© sÃ­ti se bÄ›hem trÃ©novÃ¡nÃ­ tak trochu â€nÃ¡hodou" najde menÅ¡Ã­ podstruktura parametrÅ¯, kterÃ¡ je pro danÃ½ Ãºkol mimoÅ™Ã¡dnÄ› dobÅ™e pÅ™izpÅ¯sobenÃ¡ a zbytek sÃ­tÄ› jÃ­ v podstatÄ› jen dÄ›lÃ¡ statistickÃ½ doprovod.
            </p>
          </div>
        </div>

      <!-- Int. Obr: Schema neuronovÃ© sÃ­tÄ› -->
        <figure class="image-card">
          <div class="image-card__frame">
          <div class="hotspot-image">
            <img src="img/neuron_network.png" alt="SchÃ©ma neuronovÃ© sÃ­tÄ›" loading="lazy" decoding="async"/>
            
            <!-- Hotspot -->
            <div class="hotspot" style="left: 24%; top: 10%;">
              <div class="hotspot__tooltip hotspot__tooltip--below" role="tooltip" hidden>
                <strong>Data, ze kterÃ½ch se model uÄÃ­</strong><br>
                ÄŒÃ­selnÃ© reprezentace textu, obrazu nebo jinÃ½ch vstupÅ¯, kterÃ© sÃ­Å¥ pÅ™ijÃ­mÃ¡ jako zÃ¡klad pro dalÅ¡Ã­ zpracovÃ¡nÃ­.
              </div>
            </div>
            
            <!-- Hotspot -->
            <div class="hotspot" style="left: 47%; top: 10%;">
              <div class="hotspot__tooltip hotspot__tooltip--below" role="tooltip" hidden>
                <strong>VÃ½poÄetnÃ­ vrstvy</strong><br>
                V tÃ©to ÄÃ¡sti sÃ­Å¥ krok za krokem kombinuje vstupnÃ­ data pomocÃ­ uzlÅ¯ a vah. PostupnÄ› se uÄÃ­ rozpoznÃ¡vat 
                dÅ¯leÅ¾itÃ© rysy a vztahy v datech â€“ od jednoduchÃ½ch vzorcÅ¯ aÅ¾ po sloÅ¾itÄ›jÅ¡Ã­ souvislosti, kterÃ© nejsou 
                na prvnÃ­ pohled patrnÃ©.
              </div>
            </div>
            
            <!-- Hotspot -->
            <div class="hotspot" style="left: 91%; top: 80%;">
              <div class="hotspot__tooltip" role="tooltip" hidden>
                <strong>VÃ½stup modelu</strong><br>
                PÅ™i trÃ©novÃ¡nÃ­ se vÃ½stupy prÅ¯bÄ›Å¾nÄ› porovnÃ¡vajÃ­ s referenÄnÃ­mi trÃ©novacÃ­mi daty. 
                Na zÃ¡kladÄ› rozdÃ­lu mezi pÅ™edpovÄ›dÃ­ a skuteÄnÃ½mi hodnotami se upravujÃ­ vÃ¡hy tak, aby model postupnÄ› 
                dokÃ¡zal samostatnÄ› predikovat sprÃ¡vnÃ½ vÃ½stup.
              </div>
            </div>
          </div>
          </div>
          <figcaption class="image-card__caption">
            <h3 class="image-card__title">SchematickÃ© znÃ¡zornÄ›nÃ­ neuronovÃ© sÃ­tÄ› urÄenÃ© ke klasifikaci fotografiÃ­ psÅ¯ a koÄek.</h3>
            <p class="image-card__meta">
              
              NeuronovÃ¡ sÃ­Å¥ je tvoÅ™ena nÄ›kolika vrstvami propojenÃ½ch â€neuronÅ¯" (uzlÅ¯). JednotlivÃ© uzly jsou spojeny vahami, kterÃ© urÄujÃ­ sÃ­lu vzÃ¡jemnÃ©ho propojenÃ­. VstupnÃ­ data (napÅ™. hodnoty pixelÅ¯ obrÃ¡zku) postupnÄ› prochÃ¡zejÃ­ sÃ­tÃ­ vrstvu po vrstvÄ›. KaÅ¾dÃ½ neuron kombinuje svÃ© vstupy pomocÃ­ vah a nelineÃ¡rnÃ­ aktivaÄnÃ­ funkce a vytvÃ¡Å™Ã­ tak dÃ­lÄÃ­ vÃ½stup.
              BÄ›hem trÃ©novÃ¡nÃ­ se vÃ¡hy tÄ›chto spojenÃ­ automaticky upravujÃ­ tak, aby sÃ­Å¥ co nejlÃ©pe rozliÅ¡ila sprÃ¡vnou kategorii, v tomto pÅ™Ã­padÄ› zda obrÃ¡zek obsahuje psa, nebo koÄku.

            </p>
          </figcaption>
        </figure>

      <p>
        Pamatujete si na tragickÃ© e-shopovÃ© chatboty, kterÃ© vÃ¡s vÃ­cemÃ©nÄ› nÃ¡hodnÄ› odkazovaly od Äerta k ÄÃ¡blu, aÅ¾ jste nakonec stejnÄ› volali na zÃ¡kaznickou linku pro trochu lidskÃ©ho pochopenÃ­? I tyto systÃ©my lze povaÅ¾ovat za formu umÄ›lÃ© inteligence, jsou vÅ¡ak velmi jednoduchÃ© a tematicky silnÄ› omezenÃ©. Typicky fungujÃ­ tak, Å¾e v textu vyhledÃ¡vajÃ­ klÃ­ÄovÃ¡ slova a na jejich zÃ¡kladÄ› vybÃ­rajÃ­ pÅ™edem pÅ™ipravenÃ© odpovÄ›di, aniÅ¾ by skuteÄnÄ› pracovaly s kontextem.
      </p>
      <p>
        To, Å¾e dnes na prvnÃ­ pohled Äasto nepoznÃ¡te, zda s vÃ¡mi komunikuje ÄlovÄ›k, nebo chatbot, je dÅ¯sledkem zÃ¡sadnÃ­ho prÅ¯lomu, kterÃ½ pÅ™inesla architektura <b>transformer</b>. Ta umoÅ¾Åˆuje modelÅ¯m zpracovÃ¡vat rÅ¯znÃ© ÄÃ¡sti textu souÄasnÄ› a vÃ½raznÄ› lÃ©pe zachytit kontext a prÃ¡vÄ› na nÄ›m se dnes lÃ¡me kÅ™emÃ­kovÃ½ chleba. Mimochodem, prÃ¡vÄ› slovo <i>transformer</i> stojÃ­ za pÃ­smenem â€T" ve zkratce <b>GPT</b>. GPT znamenÃ¡ Generative Pre-trained Transformer:
      </p>
      <ul>
        <li><b>generative</b> â€“ model vytvÃ¡Å™Ã­ novÃ½ obsah,</li>
        <li><b>pre-trained</b> â€“ je pÅ™edtrÃ©novÃ¡n na rozsÃ¡hlÃ½ch datech,</li>
        <li><b>transformer</b> â€“ vyuÅ¾Ã­vÃ¡ architekturu zaloÅ¾enou na mechanismu attention.</li>
      </ul>
      <p>
        Zkratka GPT tedy neoznaÄuje jeden konkrÃ©tnÃ­ model (napÅ™Ã­klad ChatGPT), ale celou rodinu pÅ™Ã­buznÃ½ch modelÅ¯, kterÃ© se liÅ¡Ã­ velikostÃ­, schopnostmi i oblastmi pouÅ¾itÃ­. VÅ¡echny tyto modely pak spadajÃ­ do Å¡irÅ¡Ã­ kategorie velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).
      </p>

        <section id="Transformery"> </section>
        <!-- Transformery a Attention -->
        <div class="collapsible" data-collapsible>
          <button class="collapsible__toggle" aria-expanded="false" aria-controls="collapsible-panel-basics-1" id="collapsible-button-basics-1">
          <b>VÃCE:</b> Transformery a attention
          </button>

          <div class="collapsible__panel" id="collapsible-panel-basics-1" role="region" aria-labelledby="collapsible-button-basics-1" hidden>
            <p>
              <b>Transformery</b> jsou typ neuronovÃ½ch sÃ­tÃ­, kterÃ© tvoÅ™Ã­ zÃ¡klad vÄ›tÅ¡iny souÄasnÃ½ch generativnÃ­ch modelÅ¯, zejmÃ©na jazykovÃ½ch modelÅ¯. Na rozdÃ­l od starÅ¡Ã­ch pÅ™Ã­stupÅ¯ nezpracovÃ¡vajÃ­ vstup postupnÄ› krok za krokem, ale pracujÃ­ s celÃ½m vstupem najednou. DÃ­ky tomu dokÃ¡Å¾ou efektivnÄ› zachytit kontext i napÅ™Ã­Ä dlouhÃ½mi texty.
            </p>
            <p>
              Jak to ty transformery dÄ›lajÃ­? KlÃ­ÄovÃ½m pojmem je zde tzv. <b>attention mechanismus</b>, kterÃ½ vyhodnocuje vztahy mezi jednotlivÃ½mi ÄÃ¡stmi vstupu. Model tak napÅ™Ã­klad dokÃ¡Å¾e urÄit, ke kterÃ©mu podstatnÃ©mu jmÃ©nu se vztahuje zÃ¡jmeno, nebo Å¾e dvÄ› vÃ½znamovÄ› souvisejÃ­cÃ­ slova patÅ™Ã­ k sobÄ›, i kdyÅ¾ jsou v textu daleko od sebe. Attention v transformerech probÃ­hÃ¡ paralelnÄ› ve vÃ­ce â€hlavÃ¡ch" (<b>attention heads</b>), z nichÅ¾ kaÅ¾dÃ¡ se bÄ›hem trÃ©novÃ¡nÃ­ mÅ¯Å¾e specializovat na jinÃ½ typ souvislostÃ­.
            </p>
            <p>
              Funguje to trochu jako <b>ÄtenÃ¡Å™skÃ½ klub</b>. VÅ¡ichni ÄlenovÃ© majÃ­ pÅ™ed sebou stejnÃ½ text, Ätou ho v kontextu celÃ©ho pÅ™Ã­bÄ›hu a zÃ¡roveÅˆ si podtrhÃ¡vajÃ­ pasÃ¡Å¾e, kterÃ© povaÅ¾ujÃ­ za zajÃ­mavÃ©. KaÅ¾dÃ½ se pÅ™itom soustÅ™edÃ­ na jinÃ© aspekty jako napÅ™Ã­klad na postavy a jejich vztahy, opakujÃ­cÃ­ se motivy, vÃ½voj dÄ›je v Äase, hlavnÃ­ tÃ©mata nebo strukturu vyprÃ¡vÄ›nÃ­. VÃ½slednÃ© porozumÄ›nÃ­ vznikÃ¡ aÅ¾ jejich kombinacÃ­, podobnÄ› jako transformer sklÃ¡dÃ¡ vÃ½stupy jednotlivÃ½ch attention heads do jednÃ© reprezentace.
            </p>
            <p>
              DÃ­ky tomu model dokÃ¡Å¾e zachytit souvislosti napÅ™Ã­Ä celÃ½m vstupem. U textu napÅ™Ã­klad rozpoznÃ¡, Å¾e pojem uvedenÃ½ na zaÄÃ¡tku odstavce je dÅ¯leÅ¾itÃ½ i pro jeho zÃ¡vÄ›r, u obrazovÃ½ch dat se zamÄ›Å™Ã­ na oblasti klÃ­ÄovÃ© pro rozpoznÃ¡nÃ­ objektu.
            </p>
            <p>
              TechnickÃ½ princip attention lze pÅ™irovnat k tomu, jak model â€rozkazuje" kaÅ¾dÃ©mu tokenu, aby se podÃ­val na ostatnÃ­ tokeny a zjistil, s kterÃ½mi mÃ¡ nejvÄ›tÅ¡Ã­ souvislost. Z kaÅ¾dÃ©ho vstupnÃ­ho tokenu se pomocÃ­ nauÄenÃ½ch lineÃ¡rnÃ­ch projekcÃ­ nejprve vytvoÅ™Ã­ tÅ™i vektorovÃ© reprezentace: <b>query</b> ($Q$), <b>key</b> ($K$) a <b>value</b> ($V$). Query je jako â€dotaz" danÃ©ho tokenu, key ukazuje charakter ostatnÃ­ch tokenÅ¯ a value nese jejich obsah, kterÃ½ lze vyuÅ¾Ã­t, pokud je relevantnÃ­. Pro kaÅ¾dÃ½ pÃ¡r tokenÅ¯ se spoÄÃ­tÃ¡ skalÃ¡rnÃ­ souÄin mezi $Q$ a $K$ (mÄ›Å™enÃ­ podobnosti), tato skÃ³re se Å¡kÃ¡lujÃ­ a normalizujÃ­ pomocÃ­ softmax na vÃ¡hy, kterÃ© urÄujÃ­, jak moc se mÃ¡ brÃ¡t v Ãºvahu kaÅ¾dÃ© value. Tento postup zpracovÃ¡nÃ­ â€vÅ¡ech vÅ¯Äi vÅ¡em" je jÃ¡drem <b>scaled dot-product attention</b>.
            </p>
            <p>
              Pro nÃ¡zornou interaktivnÃ­ vizualizaci a popis doporuÄujeme: <a href="https://poloclub.github.io/transformer-explainer/" target="_blank" rel="noopener noreferrer">Transformer Explainer</a>.
            </p>

          </div>
        </div>

        <!-- Jak se uÄÃ­ -->
        <section id="JakSeUci"> </section>
        <h1>Jak se LLM uÄÃ­</h1>
        <p>
          VelkÃ© jazykovÃ© modely (LLM) se uÄÃ­ z obrovskÃ©ho mnoÅ¾stvÃ­ textu, kterÃ© jejich tvÅ¯rci zÃ­skali (ne vÅ¾dy zcela legÃ¡lnÄ›) pÅ™edevÅ¡Ã­m z internetu. JednotlivÃ­ poskytovatelÃ© modelÅ¯ pouÅ¾Ã­vajÃ­ rÅ¯znÃ© metody filtrovÃ¡nÃ­, spoleÄnÃ½m cÃ­lem je vÅ¡ak zÃ­skat jazykovÄ› bohatÃ½ a dostateÄnÄ› kvalitnÃ­ trÃ©novacÃ­ materiÃ¡l, ze kterÃ©ho se model nauÄÃ­ obecnÃ© jazykovÃ© struktury i specializovanÄ›jÅ¡Ã­ styly psanÃ­.
        </p>
        <p>
          Kdyby model trÃ©noval bez filtru tÅ™eba jen na nÃ¡hodnÃ©m vÃ½bÄ›ru z Redditu, nauÄil by se sice rychle reagovat, ale zÃ¡roveÅˆ by si osvojil Å™adu zvlÃ¡Å¡tnÃ­ch nÃ¡vykÅ¯, kterÃ© u asistenta vÄ›tÅ¡inou nechceme.
        </p>
        <p>
          Je takÃ© velmi dÅ¯leÅ¾itÃ© mÃ­t na pamÄ›ti, Å¾e jazykovÃ½ model:
        </p>
        <ul>
          <li>pÅ™i odpovÃ­dÃ¡nÃ­ neÄerpÃ¡ z pÅ¯vodnÃ­ databÃ¡ze zdrojÅ¯,</li>
          <li>nepamatuje si konkrÃ©tnÃ­ dokumenty pouÅ¾itÃ© pÅ™i trÃ©ninku,</li>
          <li>aktivnÄ› nevyhledÃ¡vÃ¡ informace, pokud k tomu nenÃ­ vÃ½slovnÄ› pÅ™ipojen (napÅ™Ã­klad pÅ™es vyhledÃ¡vaÄ).</li>
        </ul>
        <p>
          ZjednoduÅ¡enÄ› Å™eÄeno, model si trÃ©novacÃ­ data uklÃ¡dÃ¡ v silnÄ› komprimovanÃ© podobÄ›. NÄ›kterÃ¡ fakta znÃ¡ lÃ©pe (ta, kterÃ¡ se v datech objevovala Äasto), jinÃ¡ si nezapamatuje vÅ¯bec. PÅ™ipomÃ­nÃ¡ to studenta, kterÃ½ se noc pÅ™ed zkouÅ¡kou nadrtil skripta: nÄ›co si pamatuje velmi pÅ™esnÄ›, nÄ›co mlhavÄ› a nÄ›co vÅ¯bec.
        </p>

        <!-- PrvnÃ­ fÃ¡ze -->
        <section id="ZakladniTrenink"> </section>
        <h2><b>PrvnÃ­ fÃ¡ze:</b> zÃ¡kladnÃ­ jazykovÃ½ trÃ©nink</h2>
        <p>V prvnÃ­ fÃ¡zi je model pÅ™edtrÃ©novÃ¡n na obrovskÃ©m mnoÅ¾stvÃ­ textÅ¯. BÄ›hem tohoto trÃ©ninku:</p>
        <ul>
          <li>dostÃ¡vÃ¡ text rozdÄ›lenÃ½ na malÃ© jednotky zvanÃ© tokeny,</li>
          <li>uÄÃ­ se pÅ™edpovÃ­dat nÃ¡sledujÃ­cÃ­ token v sekvenci,</li>
          <li>postupnou optimalizacÃ­ miliard parametrÅ¯ si vytvÃ¡Å™Ã­ vnitÅ™nÃ­ reprezentaci jazykovÃ½ch vzorÅ¯.</li>
        </ul>
        <p>
          VÃ½sledkem je neuronovÃ¡ sÃ­Å¥ s natrÃ©novanÃ½mi parametry (vÄetnÄ› mechanismÅ¯ attention), kterÃ¡ velmi dobÅ™e ovlÃ¡dÃ¡ jazyk. NeuÄÃ­ se vÅ¡ak fakta jako poloÅ¾ky v databÃ¡zi. MÃ­sto toho si osvojuje statistickÃ© zÃ¡vislosti jazyka a vÃ­, co obvykle nÃ¡sleduje po Äem, co spolu souvisÃ­ a co znÃ­ pravdÄ›podobnÄ›.
        </p>
        <p>
          Po tÃ©to fÃ¡zi mÃ¡me hotovÃ©ho jazykovÃ©ho specialistuâ€“asociÃ¡la: perfektnÄ› ovlÃ¡dÃ¡ jazyk, ale netuÅ¡Ã­, jak komunikovat s lidmi. UmÃ­ generovat text, ale nevÃ­, Å¾e mÃ¡ bÃ½t uÅ¾iteÄnÃ½, sluÅ¡nÃ½ nebo Å¾e by mÄ›l odpovÃ­dat na otÃ¡zky. To pÅ™ichÃ¡zÃ­ aÅ¾ v dalÅ¡Ã­ fÃ¡zi vÃ½cviku.
        </p>

        <!-- DruhÃ¡ fÃ¡ze -->
        <section id="Finetuning"> </section>
        <h2><b>DruhÃ¡ fÃ¡ze:</b> doladÄ›nÃ­ a interakce</h2>
        <p><i>Aneb nejde o to, co jsi Å™ekl, ale jak jsi to Å™ekl!!!</i></p>
        <p>
          SamotnÃ½ jazykovÃ½ asociÃ¡l by pÅ™Ã­liÅ¡ uÅ¾iteÄnÃ½ nebyl, proto nÃ¡sleduje dalÅ¡Ã­ fÃ¡ze vzdÄ›lÃ¡vÃ¡nÃ­, oznaÄovanÃ¡ jako <b>doladÄ›nÃ­</b> (fine-tuning). V tÃ©to fÃ¡zi se model uÄÃ­ reagovat na instrukce a komunikovat s ÄlovÄ›kem. PouÅ¾Ã­vajÃ­ se napÅ™Ã­klad:
        </p>
        <ul>
          <li>vzorovÃ© otÃ¡zky a odpovÄ›di,</li>
          <li>pÅ™edepsanÃ© dialogy,</li>
          <li>instrukce typu shrÅˆ, vysvÄ›tli, porovnej, navrhni.</li>
        </ul>
        <p>
          Model se tak neuÄÃ­ jen co Å™Ã­kat, ale i jak to Å™Ã­kat. Tato fÃ¡ze je klÃ­ÄovÃ¡ pro to, aby LLM nepÅ¯sobil jako nÃ¡hodnÃ½ generÃ¡tor textu, ale jako asistent, kterÃ½ smysluplnÄ› reaguje na zadÃ¡nÃ­.
        </p>

        <!-- TÅ™etÃ­ fÃ¡ze -->
        <section id="Reinforcement"> </section>
        <h2>Reinforcement learning: vÃ½cvik na lidech</h2>
        <p>
          NÄ›kterÃ© modely prochÃ¡zejÃ­ jeÅ¡tÄ› dalÅ¡Ã­ fÃ¡zÃ­ zvanou <b>reinforcement learning from human feedback (RLHF)</b>, tedy uÄenÃ­m z lidskÃ© zpÄ›tnÃ© vazby. Tato fÃ¡ze uÅ¾ nepÅ™idÃ¡vÃ¡ novÃ© znalosti o svÄ›tÄ›, ale uÄÃ­ model, jak se chovat, aby jeho odpovÄ›di byly pro lidi uÅ¾iteÄnÃ© a pÅ™ijatelnÃ©.
        </p>
        <p>Proces probÃ­hÃ¡ zhruba takto:</p>
        <ul>
          <li>model vygeneruje nÄ›kolik moÅ¾nÃ½ch odpovÄ›dÃ­ na stejnÃ½ dotaz,</li>
          <li>lidÃ© (hodnotitelÃ©) tyto odpovÄ›di porovnajÃ­ a oznaÄÃ­ ty, kterÃ© jsou uÅ¾iteÄnÄ›jÅ¡Ã­, pÅ™esnÄ›jÅ¡Ã­ nebo stylisticky vhodnÄ›jÅ¡Ã­,</li>
          <li>model se postupnÄ› uÄÃ­ preferovat odpovÄ›di, kterÃ© lidÃ© hodnotÃ­ lÃ©pe.</li>
        </ul>
        <p>
          CelÃ½ proces lze dobÅ™e pÅ™irovnat ke kynologickÃ©mu vÃ½cviku. Model zkouÅ¡Ã­ rÅ¯znÃ© triky a podle reakce lidÃ­ se uÄÃ­, kterÃ© z nich mÃ¡ opakovat ÄastÄ›ji. A stejnÄ› jako u vÃ½cviku psa platÃ­, Å¾e zÃ¡leÅ¾Ã­ na tom, kdo drÅ¾Ã­ pamlsky. Model se neuÄÃ­ sprÃ¡vnÃ© odpovÄ›di, ale ty, kterÃ© konkrÃ©tnÃ­ skupina lidÃ­ povaÅ¾uje za Å¾Ã¡doucÃ­.
        </p>
        <p>
          VÃ½sledkem je model, kterÃ½ se nauÄil pÅ™edevÅ¡Ã­m to, jak odpovÃ­dat tak, aby to lidem vyhovovalo.
        </p>

        <!-- UmÄ›nÃ­ dialogu -->
        <h2>UmÄ›nÃ­ dialogu</h2>
        <p>
          Na zÃ¡kladÄ› vzorovÃ½ch konverzacÃ­ se model uÄÃ­ vÃ©st plynulÃ½ dialog. RozliÅ¡uje roli uÅ¾ivatele a asistenta, uÄÃ­ se navazovat na pÅ™edchozÃ­ odpovÄ›di, reagovat na doplÅˆujÃ­cÃ­ otÃ¡zky a udrÅ¾ovat kontext v prÅ¯bÄ›hu konverzace.
        </p>
        <p>
          PodobnÄ› jako student u ÃºstnÃ­ zkouÅ¡ky jsou konverzaÄnÃ­ LLM vycviÄeny tak, aby vÅ¾dy nÄ›jak odpovÄ›dÄ›ly, i kdyÅ¾ si nejsou ÃºplnÄ› jistÃ©. To je v praxi Äasto uÅ¾iteÄnÃ©, ale zÃ¡roveÅˆ to vede k jevu zvanÃ©mu <b>halucinace</b>: model odpovÃ­dÃ¡ sebevÄ›domÄ› i tam, kde ve skuteÄnosti Å¾Ã¡dnou spolehlivou informaci nemÃ¡.
        </p>

        <h2>Co se model neuÄÃ­</h2>
        <p>
          I kdyÅ¾ jazykovÃ© modely Äasto pÅ¯sobÃ­ velmi sebejistÄ›, je dobrÃ© mÃ­t na pamÄ›ti, Å¾e se:
        </p>
        <ul>
          <li>neuÄÃ­ logiku ve smyslu formÃ¡lnÃ­ch pravidel nebo dÅ¯kazÅ¯,</li>
          <li>neuÄÃ­ metodologii vÃ½zkumu,</li>
          <li>neuÄÃ­ se fakta jako poloÅ¾ky v databÃ¡zi,</li>
          <li>neuÄÃ­ se ovÄ›Å™ovat pravdivost informacÃ­,</li>
          <li>nerozliÅ¡ujÃ­ pravdu a nepravdu jako takovou.</li>
        </ul>
        <p>
          Model v zÃ¡sadÄ› pouze odhaduje, co by mÄ›lo pravdÄ›podobnÄ› nÃ¡sledovat, nikoli to, co je skuteÄnÄ› pravda. To, Å¾e odpovÄ›Ä znÃ­ rozumnÄ› a plynule, tedy jeÅ¡tÄ› neznamenÃ¡, Å¾e je sprÃ¡vnÃ¡.
        </p>

        <!-- Jak chÃ¡pe text -->
        <section id="JakChapeText"> </section>
        <h1>Jak LLM â€chÃ¡pe" text</h1>
        <p>
          KdyÅ¾ ÄlovÄ›k Äte text, pracuje s vÃ½znamem. ChÃ¡pe slova, vÄ›ty, souvislosti a Äte mezi Å™Ã¡dky. JazykovÃ½ model tohle neumÃ­ a proto si musÃ­ text nejdÅ™Ã­v pÅ™edÅ¾vÃ½kat do podoby, kterÃ© jeho kÅ™emÃ­kovÃ½ mozek rozumÃ­. Jinak by si nepÅ™eÄetl ani BabiÄku.
        </p>
        <p>
          PrvnÃ­m krokem je tokenizace. Text se rozdÄ›lÃ­ na malÃ© kousky, takzvanÃ© <a href="#Tokeny">tokeny</a>. Ty Äasto neodpovÃ­dajÃ­ celÃ½m slovÅ¯m, ale mÅ¯Å¾e jÃ­t o ÄÃ¡st slova, interpunkci, mezeru nebo jejich kombinaci. KaÅ¾dÃ©mu tokenu odpovÃ­dÃ¡ jednoznaÄnÃ¡ ÄÃ­selnÃ¡ hodnota, takÅ¾e vÃ½sledkem uÅ¾ nenÃ­ text, ale posloupnost ÄÃ­sel. A prÃ¡vÄ› s touhle ÄÃ­selnou verzÃ­ jazyka model dÃ¡l pracuje.
        </p>

        <h3>Jak to vidÃ­ model: vyzkouÅ¡ejte si tokenizaci</h3>
        <p>
          NevÄ›Å™Ã­te, Å¾e model â€nevidÃ­" slova, ale jen tokeny? Zkuste si to sami. Zadejte libovolnou vÄ›tu a podÃ­vejte se, na jakÃ© tokeny ji model rozdÄ›lÃ­. ÄŒasto to nejsou kousky, kterÃ© by ÄlovÄ›ka napadly na prvnÃ­ dobrou.
        </p>

        <!-- Tokenizer Demo -->
        <div id="tokenizer-demo" class="tokenizer-demo">
          <textarea class="tokenizer-demo__input" placeholder="NapiÅ¡te nebo vloÅ¾te text...">â€Dejte na vÅ¡ecko pozor, ohlÃ­dnÄ›te se po drÅ¯beÅ¾i!" pÅ™ikazuje babiÄka. SultÃ¡n chce Adelce se lichotit, ÄuchÃ¡ k vÄ›ncÅ¯m, kterÃ© nese v ruce, ale ona zdvihÃ¡ obÄ› ruce vzhÅ¯ru a babiÄka odhÃ¡nÃ­ ho Å™kouc: â€NevidÃ­Å¡, ty hloupÃ½, Å¾e je Adelka druÅ¾iÄkou?"</textarea>
          
          <div class="tokenizer-demo__results">
            <div class="tokenizer-demo__stats">
              <div class="tokenizer-demo__stat">
                <span class="tokenizer-demo__stat-value">0</span>
                <span class="tokenizer-demo__stat-label">tokenÅ¯</span>
              </div>
              <div class="tokenizer-demo__stat">
                <span class="tokenizer-demo__stat-value">0</span>
                <span class="tokenizer-demo__stat-label">znakÅ¯</span>
              </div>
              <div class="tokenizer-demo__stat">
                <span class="tokenizer-demo__stat-value">0</span>
                <span class="tokenizer-demo__stat-label">tokenu na znak</span>
              </div>
            </div>
            <div class="tokenizer-demo__visual"></div>
            <div class="tokenizer-demo__tokens"></div>
            <p class="tokenizer-demo__note">PoznÃ¡mka: KaÅ¾dÃ½ model mÃ¡ vlastnÃ­ tokenizÃ©r. StejnÃ½ text tak mÅ¯Å¾e bÃ½t rÅ¯znÃ½mi modely rozdÄ›len na odliÅ¡nÃ½ poÄet tokenÅ¯.</p>
          </div>
        </div>

        <p>
          SamotnÃ¡ ÄÃ­sla by ale byla dost neuÅ¾iteÄnÃ¡, takÅ¾e pÅ™ichÃ¡zÃ­ dalÅ¡Ã­ krok: <a href="#Embeddingy">embeddingy</a>. KaÅ¾dÃ©mu tokenu je pÅ™iÅ™azen vektor ve velmi vysokodimenzionÃ¡lnÃ­m prostoru (Å™Ã¡dovÄ› tisÃ­ce rozmÄ›rÅ¯). Tento vektor funguje jako ÄÃ­selnÃ½ otisk vÃ½znamu a kontextu.
        </p>
        <p>
          ExistujÃ­ i specializovanÃ© embeddingovÃ© modely, jejichÅ¾ jedinÃ½m Ãºkolem je pÅ™evÃ¡dÄ›t text do tohoto vektorovÃ©ho prostoru. AÅ¥ uÅ¾ jde o samostatnÃ½ model, nebo souÄÃ¡st LLM, vÃ½sledkem je prostor, v nÄ›mÅ¾ jsou vektory uspoÅ™Ã¡dÃ¡ny tak, Å¾e vÃ½znamovÄ› podobnÃ© tokeny leÅ¾Ã­ blÃ­zko sebe, zatÃ­mco nesouvisejÃ­cÃ­ pojmy jsou od sebe vzdÃ¡lenÃ©.
        </p>
        <p>
          S takto vzniklÃ½mi vektory lze pracovat jak jste zvyklÃ­ z geometrie, tj. lze je sÄÃ­tat, odeÄÃ­tat a porovnÃ¡vat jejich smÄ›r i vzdÃ¡lenost. ZajÃ­mavÃ© je, Å¾e se v embeddingovÃ©m prostoru objevujÃ­ konzistentnÃ­ vÃ½znamovÃ© vztahy. KlasickÃ½m (a dnes uÅ¾ legendÃ¡rnÃ­m) pÅ™Ã­kladem je:
        </p>
        <p style="text-align: center; font-size: 1.2em;">
          $$\overrightarrow{\text{krÃ¡l}} - \overrightarrow{\text{muÅ¾}} + \overrightarrow{\text{Å¾ena}} \approx \overrightarrow{\text{krÃ¡lovna}}$$
        </p>
        <p>
          Model samozÅ™ejmÄ› netuÅ¡Ã­, co je monarchie nebo pohlavÃ­. Jen se z dat nauÄil, Å¾e urÄitÃ½ vÃ½znamovÃ½ rozdÃ­l se v tomto prostoru chovÃ¡ jako konzistentnÃ­ smÄ›r. PodobnÃ© â€smÄ›ry" odpovÃ­dajÃ­ rÅ¯znÃ½m vÃ½znamovÃ½m aspektÅ¯m. DÅ¯leÅ¾itÃ© je, Å¾e u modernÃ­ch LLM nenÃ­ vÃ½znam slova pevnÄ› danÃ½. StejnÃ© slovo mÃ¡ jinou reprezentaci podle kontextu a proto â€klÃ­Ä" ve vÄ›tÄ› â€ztratil jsem klÃ­Ä od dveÅ™Ã­" a â€namaluj houslovÃ½ klÃ­Ä" skonÄÃ­ na ÃºplnÄ› jinÃ½ch mÃ­stech v embedding prostoru.
        </p>

        <h3>ChÃ¡pe to tedy model jako ÄlovÄ›k?</h3>
        <p>
          Ne. LLM nepracuje s vÃ½znamem ani zÃ¡mÄ›rem. NemÃ¡ plÃ¡n, nevÃ­, â€o Äem mluvÃ­", a nic si nepÅ™edstavuje. DÄ›lÃ¡ jednu jedinou vÄ›c: predikuje dalÅ¡Ã­ token, kterÃ½ je v danÃ©m kontextu nejpravdÄ›podobnÄ›jÅ¡Ã­.
        </p>
        <p>
          ZnÃ­ to banÃ¡lnÄ› â€“ skoro jako chytrÃ½ naÅ¡eptÃ¡vaÄ. JenÅ¾e kombinace:
        </p>
        <ul>
          <li>obrovskÃ©ho mnoÅ¾stvÃ­ dat,</li>
          <li>vysokÃ© dimenzionality embeddingÅ¯,</li>
          <li>a sofistikovanÃ© architektury (transformery, attention)</li>
        </ul>
        <p>
          vede k chovÃ¡nÃ­, kterÃ© velmi pÅ™esvÄ›dÄivÄ› pÅ™ipomÃ­nÃ¡ porozumÄ›nÃ­. A pÅ™ekvapivÄ› Äasto to staÄÃ­.
        </p>

        <!-- HistorickÃ© okÃ©nko: word2vec -->
        <div class="collapsible" data-collapsible>
          <button class="collapsible__toggle" aria-expanded="false" aria-controls="collapsible-panel-word2vec" id="collapsible-button-word2vec">
          <b>VÃCE:</b> HistorickÃ© okÃ©nko: word2vec a TomÃ¡Å¡ Mikolov
          </button>

          <div class="collapsible__panel" id="collapsible-panel-word2vec" role="region" aria-labelledby="collapsible-button-word2vec" hidden>
            <p>
              MyÅ¡lenka reprezentovat slova jako body ve vÃ­cerozmÄ›rnÃ©m prostoru se vÃ½raznÄ› prosadila kolem roku 2013 dÃ­ky modelu <b>word2vec</b>, jehoÅ¾ hlavnÃ­m autorem byl TomÃ¡Å¡ Mikolov (tehdy Google Research). Word2vec ukÃ¡zal, Å¾e pouhÃ½m sledovÃ¡nÃ­m kontextu slov ve velkÃ½ch textech lze zachytit vÃ½znamovÃ© vztahy â€“ bez ruÄnÄ› definovanÃ½ch pravidel nebo slovnÃ­kÅ¯.
            </p>
            <p>
              TehdejÅ¡Ã­ modely pracovaly se statickÃ½mi embeddingy, kde mÄ›lo kaÅ¾dÃ© slovo jednu pevnou reprezentaci. ModernÃ­ jazykovÃ© modely tuto myÅ¡lenku rozÅ¡iÅ™ujÃ­ o kontextovÃ© embeddingy, kde se vÃ½znam slova mÄ›nÃ­ podle okolnÃ­ho textu. ZÃ¡kladnÃ­ princip ale zÅ¯stÃ¡vÃ¡ stejnÃ½: vÃ½znam vznikÃ¡ z dat a projevuje se geometricky.
            </p>
          </div>
        </div>

        <!-- Jak LLM vybÃ­rÃ¡ dalÅ¡Ã­ slovo -->
        <section id="JakVybiraSlovo"> </section>
        <h1>Jak LLM vybÃ­rÃ¡ dalÅ¡Ã­ slovo</h1>
        <p>
          KdyÅ¾ jazykovÃ½ model generuje text, nehledÃ¡ jedno jedinÃ© â€sprÃ¡vnÃ©" slovo, kterÃ© by mÄ›lo nÃ¡sledovat. V kaÅ¾dÃ©m kroku nejprve proÅ¾ene vstup pÅ™es attention mechanismy a neuronovou sÃ­Å¥ a na jejich zÃ¡kladÄ› vytvoÅ™Ã­ pravdÄ›podobnostnÃ­ rozdÄ›lenÃ­ nad vÅ¡emi tokeny, kterÃ© mÃ¡ ve svÃ©m slovnÃ­ku.
        </p>
        <p>
          VÃ½sledkem tedy nenÃ­ odpovÄ›Ä typu â€tady je dalÅ¡Ã­ slovo", ale spÃ­Å¡ nÄ›co jako:
        </p>
        <p style="margin-left: 2em; font-style: italic;">
          â€TÄ›chto deset tokenÅ¯ dÃ¡vÃ¡ smysl, tyhle tÅ™i jsou hodnÄ› pravdÄ›podobnÃ©, pÃ¡r dalÅ¡Ã­ch by se jeÅ¡tÄ› dalo zkousnout a zbytek je spÃ­Å¡ nesmysl."
        </p>
        <p>
          Teprve z tohoto rozdÄ›lenÃ­ se jeden token vybere a prÃ¡vÄ› zpÅ¯sob, jakÃ½m se vybÃ­rÃ¡, mÃ¡ zÃ¡sadnÃ­ vliv na to, jak budou odpovÄ›di modelu pÅ¯sobit.
        </p>

        <h3>Nejde o vÃ½bÄ›r, ale o losovÃ¡nÃ­</h3>
        <p>
          ÄŒasto se Å™Ã­kÃ¡, Å¾e LLM produkujÃ­ â€nejpravdÄ›podobnÄ›jÅ¡Ã­" pokraÄovÃ¡nÃ­ textu. To ale nenÃ­ ÃºplnÄ› pÅ™esnÃ©. JazykovÃ½ model si v kaÅ¾dÃ©m kroku vytvoÅ™Ã­ pravdÄ›podobnostnÃ­ rozdÄ›lenÃ­ moÅ¾nÃ½ch pokraÄovÃ¡nÃ­ a z nÄ›j losuje dalÅ¡Ã­ token. Tokeny s vyÅ¡Å¡Ã­ pravdÄ›podobnostÃ­ majÃ­ vÄ›tÅ¡Ã­ Å¡anci, Å¾e budou vybrÃ¡ny, ale nenÃ­ to Å¾Ã¡dnÃ¡ jistota.
        </p>
        <p>
          DÃ­ky tomu:
        </p>
        <ul>
          <li>odpovÄ›di nejsou pokaÅ¾dÃ© ÃºplnÄ› stejnÃ©,</li>
          <li>model mÅ¯Å¾e bÃ½t kreativnÃ­,</li>
          <li>ale zÃ¡roveÅˆ se mÅ¯Å¾e i â€utrhnout ze Å™etÄ›zu".</li>
        </ul>

        <!-- ObrÃ¡zek: NastavenÃ­ teploty v Google AI Studio -->
        <figure class="image-card image-card--thumbnail">
          <div class="image-card__frame">
            <div class="thumbnail" data-full="img/teplota.png">
              <img src="img/teplota.png" alt="NastavenÃ­ Temperature a Top P v Google AI Studio" loading="lazy" decoding="async"/>
            </div>
          </div>
          <figcaption class="image-card__caption">
            <h3 class="image-card__title">NastavenÃ­ Temperature a Top P</h3>
            <p class="image-card__meta">
              KliknÄ›te pro zvÄ›tÅ¡enÃ­.
            </p>
          </figcaption>
        </figure>

        <p>
          V nÄ›kterÃ½ch LLM nÃ¡strojÃ­ch mÃ¡ uÅ¾ivatel moÅ¾nost pravidla tÃ©to ruskÃ© rulety ovlivnit explicitnÃ­m nastavenÃ­m parametrÅ¯ jako je teplota, top-k nebo top-p.
        </p>

        <h3>Teplota: jak moc se mÅ¯Å¾e model odvÃ¡zat</h3>
        <p>
          <a href="#Temperature">Teplota</a> (temperature) urÄuje, jak moc se model pÅ™i losovÃ¡nÃ­ drÅ¾Ã­ tÄ›ch nejpravdÄ›podobnÄ›jÅ¡Ã­ch moÅ¾nostÃ­.
        </p>
        <ul>
          <li><strong>NÃ­zkÃ¡ teplota â†’ model hraje na jistotu</strong><br>
          VybÃ­rÃ¡ hlavnÄ› nejpravdÄ›podobnÄ›jÅ¡Ã­ tokeny. VÃ½stupy jsou konzistentnÃ­, opatrnÃ© a Äasto trochuâ€¦ nudnÃ©.</li>
          <li><strong>VyÅ¡Å¡Ã­ teplota â†’ model vÃ­c experimentuje</strong><br>
          Do hry se dostÃ¡vajÃ­ i mÃ©nÄ› pravdÄ›podobnÃ© tokeny. Text mÅ¯Å¾e bÃ½t kreativnÄ›jÅ¡Ã­, originÃ¡lnÄ›jÅ¡Ã­, ale Äasto taky ÃºplnÄ› mimo.</li>
        </ul>

        <!-- Info bublina: ProÄ se tomu Å™Ã­kÃ¡ teplota -->
        <div class="collapsible" data-collapsible>
          <button class="collapsible__toggle" aria-expanded="false" aria-controls="collapsible-panel-teplota" id="collapsible-button-teplota">
          <b>VÃCE:</b> ProÄ se tomu Å™Ã­kÃ¡ â€teplota" (a kdo se tu vlastnÄ› zahÅ™Ã­vÃ¡)
          </button>

          <div class="collapsible__panel" id="collapsible-panel-teplota" role="region" aria-labelledby="collapsible-button-teplota" hidden>
            <p>
              PÅ™i generovÃ¡nÃ­ textu jazykovÃ½ model nejprve spoÄÃ­tÃ¡ pro kaÅ¾dÃ½ moÅ¾nÃ½ dalÅ¡Ã­ token skÃ³re (tzv. logit), kterÃ© vyjadÅ™uje, jak dobÅ™e danÃ½ token zapadÃ¡ do kontextu. Tato skÃ³re se nÃ¡slednÄ› pÅ™evÃ¡dÄ›jÃ­ na pravdÄ›podobnosti pomocÃ­ funkce zvanÃ© <em>softmax</em>:
            </p>
            <p style="text-align: center; font-size: 1.2em;">
              $$P(\text{token}_i) = \frac{e^{z_i / T}}{\sum_j e^{z_j / T}}$$
            </p>
            <p>
              kde \(z_i\) je skÃ³re (logit) tokenu, \(T\) je teplota a jmenovatel zajiÅ¡Å¥uje, Å¾e souÄet vÅ¡ech pravdÄ›podobnostÃ­ je roven 1. Softmax se aplikuje na konci kaÅ¾dÃ©ho generaÄnÃ­ho kroku. NeuronovÃ¡ sÃ­Å¥ nejprve vypoÄÃ­tÃ¡ surovÃ¡ skÃ³re pro vÅ¡echny tokeny ve slovnÃ­ku a softmax je pÅ™evede na pravdÄ›podobnostnÃ­ rozdÄ›lenÃ­, ze kterÃ©ho se nÃ¡slednÄ› jeden token vybere (vzorkovÃ¡nÃ­m). PrÃ¡vÄ› v tomto kroku se uplatÅˆuje teplota i dalÅ¡Ã­ parametry generovÃ¡nÃ­.
            </p>
            <p>
              Tvar tÃ©to rovnice nenÃ­ nÃ¡hodnÃ½ â€“ exponenciÃ¡lnÃ­ Älen je stejnÃ½ jako v <em>BoltzmannovÄ› rozdÄ›lenÃ­</em> ze statistickÃ© fyziky. Tam teplota urÄuje, jak snadno systÃ©m pÅ™echÃ¡zÃ­ do mÃ©nÄ› pravdÄ›podobnÃ½ch (vyÅ¡Å¡Ã­ch energetickÃ½ch) stavÅ¯. U jazykovÃ½ch modelÅ¯ hraje teplota stejnou roli: urÄuje, jak snadno model sÃ¡hne po mÃ©nÄ› pravdÄ›podobnÃ©m tokenu.
            </p>
            <p>
              <strong>Co se stane pÅ™i velmi nÃ­zkÃ© teplotÄ›?</strong><br>
              PÅ™i \(T \to 0\) se rozdÃ­ly mezi skÃ³re v exponenciÃ¡le extrÃ©mnÄ› zesÃ­lÃ­, takÅ¾e tÃ©mÄ›Å™ veÅ¡kerÃ¡ pravdÄ›podobnost â€spadne" na jedinÃ½ nejlÃ©pe hodnocenÃ½ token. LosovÃ¡nÃ­ se tÃ­m pÃ¡dem prakticky zmÄ›nÃ­ v deterministickÃ½ vÃ½bÄ›r a model pokaÅ¾dÃ© Å™ekne to samÃ©.
            </p>
            <p>
              <strong>StruÄnÄ›:</strong>
            </p>
            <ul>
              <li>nÃ­zkÃ¡ teplota â†’ jistota, opakovatelnost, minimum pÅ™ekvapenÃ­,</li>
              <li>vyÅ¡Å¡Ã­ teplota â†’ rozmanitost, kreativita, ale i vÄ›tÅ¡Ã­ riziko nesmyslÅ¯.</li>
            </ul>
            <p>
              <em>JazykovÃ½ model se pÅ™i vyÅ¡Å¡Ã­ teplotÄ› skuteÄnÄ› nezahÅ™Ã­vÃ¡. To, co se zahÅ™Ã­vÃ¡, je datacentrum, ve kterÃ©m bÄ›Å¾Ã­... a nÄ›kdy docela dost.</em> ğŸ”¥
            </p>
          </div>
        </div>

        <h3>Top-k a top-p: z jak velkÃ©ho klobouku losujeme</h3>
        <p>
          DalÅ¡Ã­ parametry Å™Ã­kajÃ­, z kolika moÅ¾nostÃ­ vÅ¯bec smÃ­ model vybÃ­rat.
        </p>
        <ul>
          <li><strong>Top-k:</strong> model si vezme k nejpravdÄ›podobnÄ›jÅ¡Ã­ch tokenÅ¯ a losuje jen z nich.<br>
          <span style="color: var(--clr-text-muted, #6b7280); font-size: 0.9em;">(NapÅ™. â€vybÃ­rej jen z 50 nejlepÅ¡Ã­ch nÃ¡vrhÅ¯.")</span></li>
          <li><strong>Top-p (nucleus sampling):</strong> model vybÃ­rÃ¡ z takovÃ©ho poÄtu tokenÅ¯, aby jejich souÄet pravdÄ›podobnostÃ­ dosÃ¡hl urÄitÃ© hranice (napÅ™. 90 %).</li>
        </ul>
        <p>
          Oba pÅ™Ã­stupy majÃ­ stejnÃ½ cÃ­l: odÅ™Ã­znout extrÃ©mnÄ› nepravdÄ›podobnÃ© nesmysly, aniÅ¾ by model musel jet ÃºplnÄ› v danÃ½ch kolejÃ­ch.
        </p>
        <p>
          KromÄ› toho lze podobnÃ©ho efektu dosÃ¡hnout jiÅ¾ instrukcÃ­ v promptu. Å˜eknÄ›te modelu napÅ™Ã­klad â€buÄ co nejvÃ­c kreativnÃ­" nebo â€drÅ¾ se pÅ™esnÄ› zadÃ¡nÃ­ a odpovÃ­dej podle tÃ©to Å¡ablony" a uvidÃ­te, Å¾e obvykle takto formulovanÃ© preference respektuje a upravÃ­ podle toho svÃ© vÃ½stupy.
        </p>
        <p>
          <strong>Model sÃ¡m o sobÄ› nenÃ­ kreativnÃ­ ani opatrnÃ½. To, jak se chovÃ¡, je pÅ™Ã­mÃ½ dÅ¯sledek toho, jak mu nastavÃ­me pravidla losovÃ¡nÃ­.</strong>
        </p>

    </div>

  </div>
</section>
